{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GenerateMCQwithBERT-summarizer-wordnet-and-conceptnet .ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPgOgSMn6jemXmfpV4DuNEg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raja-mishra1/Mcq-s-with-Bert-summariser/blob/master/GenerateMCQwithBERT_summarizer_wordnet_and_conceptnet_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr5risMA-cFT",
        "colab_type": "code",
        "outputId": "d9a43a72-cf5b-4475-aca8-674bc49928f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Get the required libraries\n",
        "\n",
        "!pip install gensim\n",
        "!pip install git+https://github.com/boudinfl/pke.git\n",
        "!python -m spacy download en\n",
        "!pip install bert-extractive-summarizer --upgrade --force-reinstall\n",
        "!pip install spacy==2.1.3 --upgrade --force-reinstall\n",
        "!pip install -U nltk\n",
        "!pip install -U pywsd"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.3)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.12.46)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.23.0)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.46 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.15.46)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.25.9)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.46->boto3->smart-open>=1.2.1->gensim) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.46->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n",
            "Collecting git+https://github.com/boudinfl/pke.git\n",
            "  Cloning https://github.com/boudinfl/pke.git to /tmp/pip-req-build-ile75qu4\n",
            "  Running command git clone -q https://github.com/boudinfl/pke.git /tmp/pip-req-build-ile75qu4\n",
            "Requirement already satisfied (use --upgrade to upgrade): pke==1.8.1 from git+https://github.com/boudinfl/pke.git in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (3.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (2.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (1.18.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (1.4.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (2.2.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (1.14.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (0.0)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (1.1.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (0.16.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (0.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk->pke==1.8.1) (4.45.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from nltk->pke==1.8.1) (2020.4.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from nltk->pke==1.8.1) (7.1.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->pke==1.8.1) (4.4.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (0.6.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (3.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (2.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (46.1.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (0.9.6)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (1.0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->pke==1.8.1) (0.22.2.post1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (1.25.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (2020.4.5.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->pke==1.8.1) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->pke==1.8.1) (3.1.0)\n",
            "Building wheels for collected packages: pke\n",
            "  Building wheel for pke (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pke: filename=pke-1.8.1-cp36-none-any.whl size=8759618 sha256=1cc10064bd6477b0ebd32902b3d4147ddbdae310596b020096732a81613b2a9c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6wf3qzg_/wheels/8d/24/54/6582e854e9e32dd6c632af6762b3a5d2f6b181c2992e165462\n",
            "Successfully built pke\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (46.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.45.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.9.6)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.25.9)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Processing /root/.cache/pip/wheels/13/bc/30/654eb9e657177a56cba927c5a20b6cd01fb229b1ed2bf9b371/bert_extractive_summarizer-0.4.2-cp36-none-any.whl\n",
            "Collecting scikit-learn\n",
            "  Using cached https://files.pythonhosted.org/packages/5e/d8/312e03adf4c78663e17d802fe2440072376fee46cada1404f1727ed77a32/scikit_learn-0.22.2.post1-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting transformers\n",
            "  Using cached https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl\n",
            "Collecting spacy\n",
            "  Using cached https://files.pythonhosted.org/packages/55/2e/ac00f5c9d01e66cc6ab75eb2a460c9b0dc21ad99a12f810c86a58309e63c/spacy-2.2.4-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting joblib>=0.11\n",
            "  Using cached https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl\n",
            "Collecting scipy>=0.17.0\n",
            "  Using cached https://files.pythonhosted.org/packages/dc/29/162476fd44203116e7980cfbd9352eef9db37c49445d1fec35509022f6aa/scipy-1.4.1-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting numpy>=1.11.0\n",
            "  Using cached https://files.pythonhosted.org/packages/3d/fc/4763e5f17ac6e7e7d55f377cde859ca1c5d5ac624441ab45315bc578aa9e/numpy-1.18.3-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Processing /root/.cache/pip/wheels/7d/79/2d/8185b561a91188bcf61eb09dbd693b59e400f1c21ffed90392/boto3-1.12.46-py2.py3-none-any.whl\n",
            "Collecting tokenizers==0.5.2\n",
            "  Using cached https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting regex!=2019.12.17\n",
            "  Using cached https://files.pythonhosted.org/packages/ac/46/ba38a04bfe4db6177ea89cde0bb7814ae677eafab8e51335729c5387ecdd/regex-2020.4.4-cp36-cp36m-manylinux2010_x86_64.whl\n",
            "Processing /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1/sacremoses-0.0.41-cp36-none-any.whl\n",
            "Collecting requests\n",
            "  Using cached https://files.pythonhosted.org/packages/1a/70/1935c770cb3be6e3a8b78ced23d7e0f3b187f5cbfab4749523ed65d7c9b1/requests-2.23.0-py2.py3-none-any.whl\n",
            "Collecting dataclasses; python_version < \"3.7\"\n",
            "  Using cached https://files.pythonhosted.org/packages/e1/d2/6f02df2616fd4016075f60157c7a0452b38d8f7938ae94343911e0fb0b09/dataclasses-0.7-py3-none-any.whl\n",
            "Collecting tqdm>=4.27\n",
            "  Using cached https://files.pythonhosted.org/packages/4a/1c/6359be64e8301b84160f6f6f7936bbfaaa5e9a4eab6cbc681db07600b949/tqdm-4.45.0-py2.py3-none-any.whl\n",
            "Collecting filelock\n",
            "  Using cached https://files.pythonhosted.org/packages/93/83/71a2ee6158bb9f39a90c0dea1637f81d5eef866e188e1971a1b1ab01a35a/filelock-3.0.12-py3-none-any.whl\n",
            "Collecting sentencepiece\n",
            "  Using cached https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting murmurhash<1.1.0,>=0.28.0\n",
            "  Using cached https://files.pythonhosted.org/packages/a6/e6/63f160a4fdf0e875d16b28f972083606d8d54f56cd30cb8929f9a1ee700e/murmurhash-1.0.2-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting srsly<1.1.0,>=1.0.2\n",
            "  Using cached https://files.pythonhosted.org/packages/0e/9a/70bd934dd4d25545c9aa6c8cd4edbac2a33ba9c915439a9209b69f0ec0ad/srsly-1.0.2-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting catalogue<1.1.0,>=0.0.7\n",
            "  Using cached https://files.pythonhosted.org/packages/6c/f9/9a5658e2f56932e41eb264941f9a2cb7f3ce41a80cb36b2af6ab78e2f8af/catalogue-1.0.0-py2.py3-none-any.whl\n",
            "Collecting thinc==7.4.0\n",
            "  Using cached https://files.pythonhosted.org/packages/73/ed/8e4559f1090fb05c0fa982a8a2caaa315967e7b460652be479d13fd1c813/thinc-7.4.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting blis<0.5.0,>=0.4.0\n",
            "  Using cached https://files.pythonhosted.org/packages/41/19/f95c75562d18eb27219df3a3590b911e78d131b68466ad79fdf5847eaac4/blis-0.4.1-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting cymem<2.1.0,>=2.0.2\n",
            "  Using cached https://files.pythonhosted.org/packages/e7/b5/3e1714ebda8fd7c5859f9b216e381adc0a38b962f071568fd00d67e1b1ca/cymem-2.0.3-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting wasabi<1.1.0,>=0.4.0\n",
            "  Using cached https://files.pythonhosted.org/packages/21/e1/e4e7b754e6be3a79c400eb766fb34924a6d278c43bb828f94233e0124a21/wasabi-0.6.0-py3-none-any.whl\n",
            "Collecting plac<1.2.0,>=0.9.6\n",
            "  Using cached https://files.pythonhosted.org/packages/86/85/40b8f66c2dd8f4fd9f09d59b22720cffecf1331e788b8a0cab5bafb353d1/plac-1.1.3-py2.py3-none-any.whl\n",
            "Collecting preshed<3.1.0,>=3.0.2\n",
            "  Using cached https://files.pythonhosted.org/packages/db/6b/e07fad36913879757c90ba03d6fb7f406f7279e11dcefc105ee562de63ea/preshed-3.0.2-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting setuptools\n",
            "  Using cached https://files.pythonhosted.org/packages/a0/df/635cdb901ee4a8a42ec68e480c49f85f4c59e8816effbf57d9e6ee8b3588/setuptools-46.1.3-py3-none-any.whl\n",
            "Collecting botocore<1.16.0,>=1.15.46\n",
            "  Using cached https://files.pythonhosted.org/packages/6c/21/d015b86c8fa291f78e8fe7d7cf0a60645989efa5db5e8302e2b7ccf9539a/botocore-1.15.46-py2.py3-none-any.whl\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Using cached https://files.pythonhosted.org/packages/a3/43/1e939e1fcd87b827fe192d0c9fc25b48c5b3368902bfb913de7754b0dc03/jmespath-0.9.5-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "  Using cached https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl\n",
            "Collecting click\n",
            "  Using cached https://files.pythonhosted.org/packages/dd/c0/4d8f43a9b16e289f36478422031b8a63b54b6ac3b1ba605d602f10dd54d6/click-7.1.1-py2.py3-none-any.whl\n",
            "Collecting six\n",
            "  Using cached https://files.pythonhosted.org/packages/65/eb/1f97cb97bfc2390a276969c6fae16075da282f5058082d4cb10c6c5c1dba/six-1.14.0-py2.py3-none-any.whl\n",
            "Collecting chardet<4,>=3.0.2\n",
            "  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\n",
            "Collecting idna<3,>=2.5\n",
            "  Using cached https://files.pythonhosted.org/packages/89/e3/afebe61c546d18fb1709a61bee788254b40e736cff7271c7de5de2dc4128/idna-2.9-py2.py3-none-any.whl\n",
            "Collecting certifi>=2017.4.17\n",
            "  Using cached https://files.pythonhosted.org/packages/57/2b/26e37a4b034800c960a00c4e1b3d9ca5d7014e983e6e729e33ea2f36426c/certifi-2020.4.5.1-py2.py3-none-any.whl\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Using cached https://files.pythonhosted.org/packages/e1/e5/df302e8017440f111c11cc41a6b432838672f5a70aa29227bf58149dc72f/urllib3-1.25.9-py2.py3-none-any.whl\n",
            "Collecting importlib-metadata>=0.20; python_version < \"3.8\"\n",
            "  Using cached https://files.pythonhosted.org/packages/ad/e4/891bfcaf868ccabc619942f27940c77a8a4b45fd8367098955bb7e152fb1/importlib_metadata-1.6.0-py2.py3-none-any.whl\n",
            "Collecting python-dateutil<3.0.0,>=2.1\n",
            "  Using cached https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl\n",
            "Collecting docutils<0.16,>=0.10\n",
            "  Using cached https://files.pythonhosted.org/packages/22/cd/a6aa959dca619918ccb55023b4cb151949c64d4d5d55b3f4ffd7eee0c6e8/docutils-0.15.2-py3-none-any.whl\n",
            "Collecting zipp>=0.5\n",
            "  Using cached https://files.pythonhosted.org/packages/b2/34/bfcb43cc0ba81f527bc4f40ef41ba2ff4080e047acb0586b56b3d017ace4/zipp-3.1.0-py3-none-any.whl\n",
            "\u001b[31mERROR: kaggle 1.5.6 has requirement urllib3<1.25,>=1.21.1, but you'll have urllib3 1.25.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.21.0, but you'll have requests 2.23.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.12.0, but you'll have six 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: joblib, numpy, scipy, scikit-learn, six, python-dateutil, urllib3, jmespath, docutils, botocore, s3transfer, boto3, tokenizers, regex, click, tqdm, sacremoses, chardet, idna, certifi, requests, dataclasses, filelock, sentencepiece, transformers, murmurhash, srsly, zipp, importlib-metadata, catalogue, plac, blis, cymem, wasabi, preshed, thinc, setuptools, spacy, bert-extractive-summarizer\n",
            "  Found existing installation: joblib 0.14.1\n",
            "    Uninstalling joblib-0.14.1:\n",
            "      Successfully uninstalled joblib-0.14.1\n",
            "  Found existing installation: numpy 1.18.3\n",
            "    Uninstalling numpy-1.18.3:\n",
            "      Successfully uninstalled numpy-1.18.3\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: six 1.14.0\n",
            "    Uninstalling six-1.14.0:\n",
            "      Successfully uninstalled six-1.14.0\n",
            "  Found existing installation: python-dateutil 2.8.1\n",
            "    Uninstalling python-dateutil-2.8.1:\n",
            "      Successfully uninstalled python-dateutil-2.8.1\n",
            "  Found existing installation: urllib3 1.25.9\n",
            "    Uninstalling urllib3-1.25.9:\n",
            "      Successfully uninstalled urllib3-1.25.9\n",
            "  Found existing installation: jmespath 0.9.5\n",
            "    Uninstalling jmespath-0.9.5:\n",
            "      Successfully uninstalled jmespath-0.9.5\n",
            "  Found existing installation: docutils 0.15.2\n",
            "    Uninstalling docutils-0.15.2:\n",
            "      Successfully uninstalled docutils-0.15.2\n",
            "  Found existing installation: botocore 1.15.46\n",
            "    Uninstalling botocore-1.15.46:\n",
            "      Successfully uninstalled botocore-1.15.46\n",
            "  Found existing installation: s3transfer 0.3.3\n",
            "    Uninstalling s3transfer-0.3.3:\n",
            "      Successfully uninstalled s3transfer-0.3.3\n",
            "  Found existing installation: boto3 1.12.46\n",
            "    Uninstalling boto3-1.12.46:\n",
            "      Successfully uninstalled boto3-1.12.46\n",
            "  Found existing installation: tokenizers 0.5.2\n",
            "    Uninstalling tokenizers-0.5.2:\n",
            "      Successfully uninstalled tokenizers-0.5.2\n",
            "  Found existing installation: regex 2020.4.4\n",
            "    Uninstalling regex-2020.4.4:\n",
            "      Successfully uninstalled regex-2020.4.4\n",
            "  Found existing installation: click 7.1.1\n",
            "    Uninstalling click-7.1.1:\n",
            "      Successfully uninstalled click-7.1.1\n",
            "  Found existing installation: tqdm 4.45.0\n",
            "    Uninstalling tqdm-4.45.0:\n",
            "      Successfully uninstalled tqdm-4.45.0\n",
            "  Found existing installation: sacremoses 0.0.41\n",
            "    Uninstalling sacremoses-0.0.41:\n",
            "      Successfully uninstalled sacremoses-0.0.41\n",
            "  Found existing installation: chardet 3.0.4\n",
            "    Uninstalling chardet-3.0.4:\n",
            "      Successfully uninstalled chardet-3.0.4\n",
            "  Found existing installation: idna 2.9\n",
            "    Uninstalling idna-2.9:\n",
            "      Successfully uninstalled idna-2.9\n",
            "  Found existing installation: certifi 2020.4.5.1\n",
            "    Uninstalling certifi-2020.4.5.1:\n",
            "      Successfully uninstalled certifi-2020.4.5.1\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: dataclasses 0.7\n",
            "    Uninstalling dataclasses-0.7:\n",
            "      Successfully uninstalled dataclasses-0.7\n",
            "  Found existing installation: filelock 3.0.12\n",
            "    Uninstalling filelock-3.0.12:\n",
            "      Successfully uninstalled filelock-3.0.12\n",
            "  Found existing installation: sentencepiece 0.1.86\n",
            "    Uninstalling sentencepiece-0.1.86:\n",
            "      Successfully uninstalled sentencepiece-0.1.86\n",
            "  Found existing installation: transformers 2.8.0\n",
            "    Uninstalling transformers-2.8.0:\n",
            "      Successfully uninstalled transformers-2.8.0\n",
            "  Found existing installation: murmurhash 1.0.2\n",
            "    Uninstalling murmurhash-1.0.2:\n",
            "      Successfully uninstalled murmurhash-1.0.2\n",
            "  Found existing installation: srsly 1.0.2\n",
            "    Uninstalling srsly-1.0.2:\n",
            "      Successfully uninstalled srsly-1.0.2\n",
            "  Found existing installation: zipp 3.1.0\n",
            "    Uninstalling zipp-3.1.0:\n",
            "      Successfully uninstalled zipp-3.1.0\n",
            "  Found existing installation: importlib-metadata 1.6.0\n",
            "    Uninstalling importlib-metadata-1.6.0:\n",
            "      Successfully uninstalled importlib-metadata-1.6.0\n",
            "  Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Found existing installation: plac 0.9.6\n",
            "    Uninstalling plac-0.9.6:\n",
            "      Successfully uninstalled plac-0.9.6\n",
            "  Found existing installation: blis 0.4.1\n",
            "    Uninstalling blis-0.4.1:\n",
            "      Successfully uninstalled blis-0.4.1\n",
            "  Found existing installation: cymem 2.0.3\n",
            "    Uninstalling cymem-2.0.3:\n",
            "      Successfully uninstalled cymem-2.0.3\n",
            "  Found existing installation: wasabi 0.6.0\n",
            "    Uninstalling wasabi-0.6.0:\n",
            "      Successfully uninstalled wasabi-0.6.0\n",
            "  Found existing installation: preshed 3.0.2\n",
            "    Uninstalling preshed-3.0.2:\n",
            "      Successfully uninstalled preshed-3.0.2\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: setuptools 46.1.3\n",
            "    Uninstalling setuptools-46.1.3:\n",
            "      Successfully uninstalled setuptools-46.1.3\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "  Found existing installation: bert-extractive-summarizer 0.4.2\n",
            "    Uninstalling bert-extractive-summarizer-0.4.2:\n",
            "      Successfully uninstalled bert-extractive-summarizer-0.4.2\n",
            "Successfully installed bert-extractive-summarizer-0.4.2 blis-0.4.1 boto3-1.12.46 botocore-1.15.46 catalogue-1.0.0 certifi-2020.4.5.1 chardet-3.0.4 click-7.1.1 cymem-2.0.3 dataclasses-0.7 docutils-0.15.2 filelock-3.0.12 idna-2.9 importlib-metadata-1.6.0 jmespath-0.9.5 joblib-0.14.1 murmurhash-1.0.2 numpy-1.18.3 plac-1.1.3 preshed-3.0.2 python-dateutil-2.8.1 regex-2020.4.4 requests-2.23.0 s3transfer-0.3.3 sacremoses-0.0.41 scikit-learn-0.22.2.post1 scipy-1.4.1 sentencepiece-0.1.86 setuptools-46.1.3 six-1.14.0 spacy-2.2.4 srsly-1.0.2 thinc-7.4.0 tokenizers-0.5.2 tqdm-4.45.0 transformers-2.8.0 urllib3-1.25.9 wasabi-0.6.0 zipp-3.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_sentencepiece",
                  "blis",
                  "boto3",
                  "botocore",
                  "certifi",
                  "chardet",
                  "cymem",
                  "dataclasses",
                  "dateutil",
                  "filelock",
                  "idna",
                  "jmespath",
                  "joblib",
                  "murmurhash",
                  "numpy",
                  "pkg_resources",
                  "plac",
                  "plac_core",
                  "plac_ext",
                  "preshed",
                  "regex",
                  "requests",
                  "sacremoses",
                  "scipy",
                  "sentencepiece",
                  "six",
                  "sklearn",
                  "spacy",
                  "srsly",
                  "summarizer",
                  "thinc",
                  "tokenizers",
                  "tqdm",
                  "transformers",
                  "urllib3",
                  "wasabi"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting spacy==2.1.3\n",
            "  Using cached https://files.pythonhosted.org/packages/52/da/3a1c54694c2d2f40df82f38a19ae14c6eb24a5a1a0dae87205ebea7a84d8/spacy-2.1.3-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting thinc<7.1.0,>=7.0.2\n",
            "  Using cached https://files.pythonhosted.org/packages/18/a5/9ace20422e7bb1bdcad31832ea85c52a09900cd4a7ce711246bfb92206ba/thinc-7.0.8-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting plac<1.0.0,>=0.9.6\n",
            "  Using cached https://files.pythonhosted.org/packages/9e/9b/62c60d2f5bc135d2aa1d8c8a86aaf84edb719a59c7f11a4316259e61a298/plac-0.9.6-py2.py3-none-any.whl\n",
            "Collecting srsly<1.1.0,>=0.0.5\n",
            "  Using cached https://files.pythonhosted.org/packages/0e/9a/70bd934dd4d25545c9aa6c8cd4edbac2a33ba9c915439a9209b69f0ec0ad/srsly-1.0.2-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting wasabi<1.1.0,>=0.2.0\n",
            "  Using cached https://files.pythonhosted.org/packages/21/e1/e4e7b754e6be3a79c400eb766fb34924a6d278c43bb828f94233e0124a21/wasabi-0.6.0-py3-none-any.whl\n",
            "Collecting cymem<2.1.0,>=2.0.2\n",
            "  Using cached https://files.pythonhosted.org/packages/e7/b5/3e1714ebda8fd7c5859f9b216e381adc0a38b962f071568fd00d67e1b1ca/cymem-2.0.3-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting murmurhash<1.1.0,>=0.28.0\n",
            "  Using cached https://files.pythonhosted.org/packages/a6/e6/63f160a4fdf0e875d16b28f972083606d8d54f56cd30cb8929f9a1ee700e/murmurhash-1.0.2-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting requests<3.0.0,>=2.13.0\n",
            "  Using cached https://files.pythonhosted.org/packages/1a/70/1935c770cb3be6e3a8b78ced23d7e0f3b187f5cbfab4749523ed65d7c9b1/requests-2.23.0-py2.py3-none-any.whl\n",
            "Collecting blis<0.3.0,>=0.2.2\n",
            "  Using cached https://files.pythonhosted.org/packages/34/46/b1d0bb71d308e820ed30316c5f0a017cb5ef5f4324bcbc7da3cf9d3b075c/blis-0.2.4-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting jsonschema<3.0.0,>=2.6.0\n",
            "  Using cached https://files.pythonhosted.org/packages/77/de/47e35a97b2b05c2fadbec67d44cfcdcd09b8086951b331d82de90d2912da/jsonschema-2.6.0-py2.py3-none-any.whl\n",
            "Collecting numpy>=1.15.0\n",
            "  Using cached https://files.pythonhosted.org/packages/3d/fc/4763e5f17ac6e7e7d55f377cde859ca1c5d5ac624441ab45315bc578aa9e/numpy-1.18.3-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting preshed<2.1.0,>=2.0.1\n",
            "  Using cached https://files.pythonhosted.org/packages/20/93/f222fb957764a283203525ef20e62008675fd0a14ffff8cc1b1490147c63/preshed-2.0.1-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting tqdm<5.0.0,>=4.10.0\n",
            "  Using cached https://files.pythonhosted.org/packages/4a/1c/6359be64e8301b84160f6f6f7936bbfaaa5e9a4eab6cbc681db07600b949/tqdm-4.45.0-py2.py3-none-any.whl\n",
            "Collecting certifi>=2017.4.17\n",
            "  Using cached https://files.pythonhosted.org/packages/57/2b/26e37a4b034800c960a00c4e1b3d9ca5d7014e983e6e729e33ea2f36426c/certifi-2020.4.5.1-py2.py3-none-any.whl\n",
            "Collecting chardet<4,>=3.0.2\n",
            "  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Using cached https://files.pythonhosted.org/packages/e1/e5/df302e8017440f111c11cc41a6b432838672f5a70aa29227bf58149dc72f/urllib3-1.25.9-py2.py3-none-any.whl\n",
            "Collecting idna<3,>=2.5\n",
            "  Using cached https://files.pythonhosted.org/packages/89/e3/afebe61c546d18fb1709a61bee788254b40e736cff7271c7de5de2dc4128/idna-2.9-py2.py3-none-any.whl\n",
            "\u001b[31mERROR: -pacy 2.2.4 has requirement blis<0.5.0,>=0.4.0, but you'll have blis 0.2.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: -pacy 2.2.4 has requirement preshed<3.1.0,>=3.0.2, but you'll have preshed 2.0.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: -pacy 2.2.4 has requirement thinc==7.4.0, but you'll have thinc 7.0.8 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kaggle 1.5.6 has requirement urllib3<1.25,>=1.21.1, but you'll have urllib3 1.25.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.21.0, but you'll have requests 2.23.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.12.0, but you'll have six 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: en-core-web-sm 2.2.5 has requirement spacy>=2.2.2, but you'll have spacy 2.1.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: cymem, preshed, numpy, blis, plac, tqdm, wasabi, murmurhash, srsly, thinc, certifi, chardet, urllib3, idna, requests, jsonschema, spacy\n",
            "  Found existing installation: cymem 2.0.3\n",
            "    Uninstalling cymem-2.0.3:\n",
            "      Successfully uninstalled cymem-2.0.3\n",
            "  Found existing installation: preshed 3.0.2\n",
            "    Uninstalling preshed-3.0.2:\n",
            "      Successfully uninstalled preshed-3.0.2\n",
            "  Found existing installation: numpy 1.18.3\n",
            "    Uninstalling numpy-1.18.3:\n",
            "      Successfully uninstalled numpy-1.18.3\n",
            "  Found existing installation: blis 0.4.1\n",
            "    Uninstalling blis-0.4.1:\n",
            "      Successfully uninstalled blis-0.4.1\n",
            "  Found existing installation: plac 1.1.3\n",
            "    Uninstalling plac-1.1.3:\n",
            "      Successfully uninstalled plac-1.1.3\n",
            "  Found existing installation: tqdm 4.45.0\n",
            "    Uninstalling tqdm-4.45.0:\n",
            "      Successfully uninstalled tqdm-4.45.0\n",
            "  Found existing installation: wasabi 0.6.0\n",
            "    Uninstalling wasabi-0.6.0:\n",
            "      Successfully uninstalled wasabi-0.6.0\n",
            "  Found existing installation: murmurhash 1.0.2\n",
            "    Uninstalling murmurhash-1.0.2:\n",
            "      Successfully uninstalled murmurhash-1.0.2\n",
            "  Found existing installation: srsly 1.0.2\n",
            "    Uninstalling srsly-1.0.2:\n",
            "      Successfully uninstalled srsly-1.0.2\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: certifi 2020.4.5.1\n",
            "    Uninstalling certifi-2020.4.5.1:\n",
            "      Successfully uninstalled certifi-2020.4.5.1\n",
            "  Found existing installation: chardet 3.0.4\n",
            "    Uninstalling chardet-3.0.4:\n",
            "      Successfully uninstalled chardet-3.0.4\n",
            "  Found existing installation: urllib3 1.25.9\n",
            "    Uninstalling urllib3-1.25.9:\n",
            "      Successfully uninstalled urllib3-1.25.9\n",
            "  Found existing installation: idna 2.9\n",
            "    Uninstalling idna-2.9:\n",
            "      Successfully uninstalled idna-2.9\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: jsonschema 2.6.0\n",
            "    Uninstalling jsonschema-2.6.0:\n",
            "      Successfully uninstalled jsonschema-2.6.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed blis-0.2.4 certifi-2020.4.5.1 chardet-3.0.4 cymem-2.0.3 idna-2.9 jsonschema-2.6.0 murmurhash-1.0.2 numpy-1.18.3 plac-0.9.6 preshed-2.0.1 requests-2.23.0 spacy-2.1.3 srsly-1.0.2 thinc-7.0.8 tqdm-4.45.0 urllib3-1.25.9 wasabi-0.6.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "blis",
                  "certifi",
                  "chardet",
                  "cymem",
                  "idna",
                  "jsonschema",
                  "murmurhash",
                  "numpy",
                  "plac",
                  "plac_core",
                  "plac_ext",
                  "preshed",
                  "requests",
                  "spacy",
                  "srsly",
                  "thinc",
                  "tqdm",
                  "urllib3",
                  "wasabi"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: nltk in /usr/local/lib/python3.6/dist-packages (3.5)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from nltk) (7.1.1)\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from nltk) (2020.4.4)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from nltk) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk) (4.45.0)\n",
            "Requirement already up-to-date: pywsd in /usr/local/lib/python3.6/dist-packages (1.2.4)\n",
            "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.6/dist-packages (from pywsd) (3.5)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from pywsd) (1.0.3)\n",
            "Requirement already satisfied, skipping upgrade: wn in /usr/local/lib/python3.6/dist-packages (from pywsd) (0.0.23)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from pywsd) (1.18.3)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from pywsd) (1.14.0)\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from nltk->pywsd) (2020.4.4)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk->pywsd) (4.45.0)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from nltk->pywsd) (7.1.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from nltk->pywsd) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->pywsd) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->pywsd) (2018.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d5-h-si-5di",
        "colab_type": "code",
        "outputId": "981b3a76-0499-4073-c5de-0187376ad362",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('popular')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSv9nKigAWO2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b4c3e6d8-70c3-4f39-cd78-9a39049921f2"
      },
      "source": [
        "#lets try summarising the text we have \n",
        "from summarizer import Summarizer\n",
        "\n",
        "f = open(\"egypt.txt\",\"r\")\n",
        "full_text = f.read()\n",
        "\n",
        "model = Summarizer()\n",
        "result = model(full_text, min_length=60, max_length = 500 , ratio = 0.4)\n",
        "\n",
        "summarized_text = ''.join(result)\n",
        "print (summarized_text)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Nile River fed Egyptian civilization for hundreds of years. It begins near the equator in Africa and flows north to the Mediterranean Sea. This soil was fertile, which means it was good for growing crops. They called this region the black land because of the fertile soil that the floods deposited. The red land was the barren desert beyond the fertile region. After the waters drained away, farmers could plant seeds in the fertile soil. Then they used a tool called a shaduf to spread the water across the fields. These innovative, or new, techniques gave them more farmland. Egyptian Crops Ancient Egyptians grew a large variety of foods. They were the first to grind wheat into flour and to mix the flour with yeast and water to make dough rise into bread. Egyptian Houses Egyptians built houses using bricks made of mud from the Nile mixed with chopped straw. Egyptians often painted walls white to reflect the blazing heat. Poorer Egyptians simply went to the roof to cool off after sunset. One ancient painting even shows a man ready to hit a catfish with a wooden hammer. A boomerang is a curved stick that returns to the person who threw it.) Going south, they raised a sail and let the winds that blew in that direction push them. The Nile provided so well for Egyptians that sometimes they had surpluses, or more goods than they needed. Ancient Egypt had no money, so people exchanged goods that they grew or made. This prosperity made life easier and provided greater opportunities for many Egyptians. For example, some ancient Egyptians learned to be scribes, people whose job was to write and keep records. Some skilled artisans erected stone or brick houses and temples. These traders took Egyptian products such as scrolls, linen, gold, and jewelry. Egyptians created a government that divided the empire into 42 provinces. Many officials worked to keep the provinces running smoothly. Priests followed formal rituals and took care of the temples. Before entering a temple, a priest bathed and put on special linen garments and white sandals. Together, the priests and the ruler held ceremonies to please the gods. In Egypt, people became slaves if they owed a debt, committed a crime, or were captured in war. Unlike other ancient African cultures, in Egyptian society men and women had fairly equal rights. For example, they could both own and manage their own property. Boys and girls also played rough physical games with balls made of leather or reeds. Boys and some girls from wealthy families went to schools run by scribes or priests. Almost all Egyptians married when they were in their early teens. Doctors believed that the heart controlled thought and the brain circulated blood, which is the opposite of what is known now. Early Egyptians created a hieroglyphic system with about 700 characters. Egyptians cut the stems into strips, pressed them, and dried them into sheets that could be rolled into scrolls. Legend says a king named Narmer united Upper and Lower Egypt. Historians divide ancient Egyptian dynasties into the Old Kingdom, the Middle Kingdom, and the New Kingdom. Egyptians believed that if the pharaoh and his subjects honored the gods, their lives would be happy. In such a case, a rival might drive him from power and start a new dynasty. The first rulers of Egypt were often buried in an underground tomb topped by mud brick. They replaced the mud brick with a small pyramid of brick or stone. A pyramid is a structure shaped like a triangle, with four sides that meet at a point. It is called a step pyramid because its sides rise in a series of giant steps. He ordered the construction of the largest pyramid ever built. One reason is that the pyramids drew attention to the tombs inside them. Grave robbers broke into the tombs to steal the treasure buried with the pharaohs. Egyptians believed that if a tomb was robbed, the person buried there could not have a happy afterlife. This was to confuse grave robbers about which passage to take. Sometimes relatives, such as the queen, were buried in the extra rooms. Tombs were supposed to be the palaces of pharaohs in the afterlife. Mourners filled the tomb with objects ranging from food to furniture that the mummified pharaoh would need. A sculpture of a dead pharaoh had “perfect” features, no matter how he really looked. Artists also followed strict rules about how to portray humans. Paintings showed a person’s head, arms, and legs from the side. Such activities included growing and preparing food, caring for animals, and building boats. Only a secret tomb built for a New Kingdom pharaoh was ever found with much of its treasure untouched. By about 2130 B.C., Egyptian kings began to lose their power to local rulers of the provinces. This period of Egyptian history is called the Middle Kingdom.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLKB8L-G3CAv",
        "colab_type": "text"
      },
      "source": [
        "Bert summariser performs pretty well summarising the important lines of the text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32tYPUpbMDdV",
        "colab_type": "text"
      },
      "source": [
        "**Keyword Extraction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLWcti4bLhk-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "01be7455-6306-43b5-ab4a-891f4a0b1163"
      },
      "source": [
        "import pprint\n",
        "import itertools\n",
        "import spacy\n",
        "spacy.load('en')\n",
        "import re\n",
        "import pke\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def get_nouns_multipartite(text):\n",
        "    out=[]\n",
        "\n",
        "    extractor = pke.unsupervised.MultipartiteRank()\n",
        "    extractor.load_document(input=text)\n",
        "    #    not contain punctuation marks or stopwords as candidates.\n",
        "    pos = {'PROPN'}\n",
        "    #pos = {'VERB', 'ADJ', 'NOUN'}\n",
        "    stoplist = list(string.punctuation)\n",
        "    stoplist += ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n",
        "    stoplist += stopwords.words('english')\n",
        "    extractor.candidate_selection(pos=pos, stoplist=stoplist)\n",
        "    # 4. build the Multipartite graph and rank candidates using random walk,\n",
        "    #    alpha controls the weight adjustment mechanism, see TopicRank for\n",
        "    #    threshold/method parameters.\n",
        "    extractor.candidate_weighting(alpha=1.1,\n",
        "                                  threshold=0.75,\n",
        "                                  method='average')\n",
        "    keyphrases = extractor.get_n_best(n=20)\n",
        "\n",
        "    for key in keyphrases:\n",
        "        out.append(key[0])\n",
        "\n",
        "    return out\n",
        "\n",
        "keywords = get_nouns_multipartite(full_text) \n",
        "print (keywords)\n",
        "filtered_keys=[]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['egyptians', 'nile river', 'egypt', 'nile', 'euphrates', 'tigris', 'old kingdom', 'red land', 'crown', 'upper', 'lower egypt', 'narmer', 'longest river', 'africa', 'mediterranean sea', 'hyksos', 'new kingdom', 'black land', 'ethiopia', 'middle kingdom']\n",
            "['egyptians', 'nile river', 'egypt', 'nile', 'old kingdom', 'red land', 'upper', 'lower egypt', 'narmer', 'africa', 'mediterranean sea', 'new kingdom', 'black land', 'middle kingdom']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLavUEJO3OH5",
        "colab_type": "text"
      },
      "source": [
        "Keywords from the text have been extracted as per their relevant importance in the sentence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvyFh8hKvUTF",
        "colab_type": "text"
      },
      "source": [
        "**Sentence Mapping**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-eNR5rS3g3t",
        "colab_type": "text"
      },
      "source": [
        "Now lets try mapping those keywords to sentences  which would be pretty useful while knowing the value of a word in a sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSX4cpE7MWU9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7ecc94d3-6561-4dc5-860c-6545e6f57bde"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "from flashtext import KeywordProcessor\n",
        "\n",
        "def tokenize_sentences(text):\n",
        "    sentences = [sent_tokenize(text)]\n",
        "    sentences = [y for x in sentences for y in x]\n",
        "    # Remove any short sentences less than 20 letters.\n",
        "    sentences = [sentence.strip() for sentence in sentences if len(sentence) > 20]\n",
        "    return sentences\n",
        "\n",
        "def get_sentences_for_keyword(keywords, sentences):\n",
        "    keyword_processor = KeywordProcessor()\n",
        "    keyword_sentences = {}\n",
        "    for word in keywords:\n",
        "        keyword_sentences[word] = []\n",
        "        keyword_processor.add_keyword(word)\n",
        "    for sentence in sentences:\n",
        "        keywords_found = keyword_processor.extract_keywords(sentence)\n",
        "        for key in keywords_found:\n",
        "            keyword_sentences[key].append(sentence)\n",
        "\n",
        "    for key in keyword_sentences.keys():\n",
        "        values = keyword_sentences[key]\n",
        "        values = sorted(values, key=len, reverse=True)\n",
        "        keyword_sentences[key] = values\n",
        "    return keyword_sentences\n",
        "\n",
        "sentences = tokenize_sentences(summarized_text)\n",
        "keyword_sentence_mapping = get_sentences_for_keyword(filtered_keys, sentences)\n",
        "        \n",
        "print (keyword_sentence_mapping)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'egyptians': ['Egyptians cut the stems into strips, pressed them, and dried them into sheets that could be rolled into scrolls.', 'The Nile provided so well for Egyptians that sometimes they had surpluses, or more goods than they needed.', 'For example, some ancient Egyptians learned to be scribes, people whose job was to write and keep records.', 'Egyptian Houses Egyptians built houses using bricks made of mud from the Nile mixed with chopped straw.', 'Egyptians believed that if a tomb was robbed, the person buried there could not have a happy afterlife.', 'Egyptians believed that if the pharaoh and his subjects honored the gods, their lives would be happy.', 'This prosperity made life easier and provided greater opportunities for many Egyptians.', 'Egyptians created a government that divided the empire into 42 provinces.', 'Early Egyptians created a hieroglyphic system with about 700 characters.', 'Poorer Egyptians simply went to the roof to cool off after sunset.', 'Almost all Egyptians married when they were in their early teens.', 'Egyptians often painted walls white to reflect the blazing heat.', 'Egyptian Crops Ancient Egyptians grew a large variety of foods.'], 'nile river': ['The Nile River fed Egyptian civilization for hundreds of years.'], 'egypt': ['In Egypt, people became slaves if they owed a debt, committed a crime, or were captured in war.', 'The first rulers of Egypt were often buried in an underground tomb topped by mud brick.', 'Ancient Egypt had no money, so people exchanged goods that they grew or made.'], 'nile': ['The Nile provided so well for Egyptians that sometimes they had surpluses, or more goods than they needed.', 'Egyptian Houses Egyptians built houses using bricks made of mud from the Nile mixed with chopped straw.'], 'old kingdom': ['Historians divide ancient Egyptian dynasties into the Old Kingdom, the Middle Kingdom, and the New Kingdom.'], 'red land': ['The red land was the barren desert beyond the fertile region.'], 'upper': ['Legend says a king named Narmer united Upper and Lower Egypt.'], 'lower egypt': ['Legend says a king named Narmer united Upper and Lower Egypt.'], 'narmer': ['Legend says a king named Narmer united Upper and Lower Egypt.'], 'africa': ['It begins near the equator in Africa and flows north to the Mediterranean Sea.'], 'mediterranean sea': ['It begins near the equator in Africa and flows north to the Mediterranean Sea.'], 'new kingdom': ['Historians divide ancient Egyptian dynasties into the Old Kingdom, the Middle Kingdom, and the New Kingdom.', 'Only a secret tomb built for a New Kingdom pharaoh was ever found with much of its treasure untouched.'], 'black land': ['They called this region the black land because of the fertile soil that the floods deposited.'], 'middle kingdom': ['Historians divide ancient Egyptian dynasties into the Old Kingdom, the Middle Kingdom, and the New Kingdom.', 'This period of Egyptian history is called the Middle Kingdom.']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRg7KiEzv5wL",
        "colab_type": "text"
      },
      "source": [
        "**Time to Generate MCQ's**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwMNExy1vh8i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1c255af0-3902-4936-8e5b-e83053e3a614"
      },
      "source": [
        "import requests\n",
        "import json\n",
        "import re\n",
        "import random\n",
        "from pywsd.similarity import max_similarity\n",
        "from pywsd.lesk import adapted_lesk\n",
        "from pywsd.lesk import simple_lesk\n",
        "from pywsd.lesk import cosine_lesk\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "# Distractors from Wordnet\n",
        "def get_distractors_wordnet(syn,word):\n",
        "    distractors=[]\n",
        "    word= word.lower()\n",
        "    orig_word = word\n",
        "    if len(word.split())>0:\n",
        "        word = word.replace(\" \",\"_\")\n",
        "    hypernym = syn.hypernyms()\n",
        "    if len(hypernym) == 0: \n",
        "        return distractors\n",
        "    for item in hypernym[0].hyponyms():\n",
        "        name = item.lemmas()[0].name()\n",
        "        #print (\"name \",name, \" word\",orig_word)\n",
        "        if name == orig_word:\n",
        "            continue\n",
        "        name = name.replace(\"_\",\" \")\n",
        "        name = \" \".join(w.capitalize() for w in name.split())\n",
        "        if name is not None and name not in distractors:\n",
        "            distractors.append(name)\n",
        "    return distractors\n",
        "\n",
        "def get_wordsense(sent,word):\n",
        "    word= word.lower()\n",
        "    \n",
        "    if len(word.split())>0:\n",
        "        word = word.replace(\" \",\"_\")\n",
        "    \n",
        "    \n",
        "    synsets = wn.synsets(word,'n')\n",
        "    if synsets:\n",
        "        wup = max_similarity(sent, word, 'wup', pos='n')\n",
        "        adapted_lesk_output =  adapted_lesk(sent, word, pos='n')\n",
        "        lowest_index = min (synsets.index(wup),synsets.index(adapted_lesk_output))\n",
        "        return synsets[lowest_index]\n",
        "    else:\n",
        "        return None\n",
        "# Distractors from http://conceptnet.io/\n",
        "def get_distractors_conceptnet(word):\n",
        "    word = word.lower()\n",
        "    original_word= word\n",
        "    if (len(word.split())>0):\n",
        "        word = word.replace(\" \",\"_\")\n",
        "    distractor_list = [] \n",
        "    url = \"http://api.conceptnet.io/query?node=/c/en/%s/n&rel=/r/PartOf&start=/c/en/%s&limit=5\"%(word,word)\n",
        "    obj = requests.get(url).json()\n",
        "\n",
        "    for edge in obj['edges']:\n",
        "        link = edge['end']['term'] \n",
        "\n",
        "        url2 = \"http://api.conceptnet.io/query?node=%s&rel=/r/PartOf&end=%s&limit=10\"%(link,link)\n",
        "        obj2 = requests.get(url2).json()\n",
        "        for edge in obj2['edges']:\n",
        "            word2 = edge['start']['label']\n",
        "            if word2 not in distractor_list and original_word.lower() not in word2.lower():\n",
        "                distractor_list.append(word2)\n",
        "                   \n",
        "    return distractor_list\n",
        "\n",
        "key_distractor_list = {}\n",
        "\n",
        "for keyword in keyword_sentence_mapping:\n",
        "    wordsense = get_wordsense(keyword_sentence_mapping[keyword][0],keyword)\n",
        "    if wordsense:\n",
        "        distractors = get_distractors_wordnet(wordsense,keyword)\n",
        "        if len(distractors) ==0:\n",
        "            distractors = get_distractors_conceptnet(keyword)\n",
        "        if len(distractors) != 0:\n",
        "            key_distractor_list[keyword] = distractors\n",
        "    else:\n",
        "        \n",
        "        distractors = get_distractors_conceptnet(keyword)\n",
        "        if len(distractors) != 0:\n",
        "            key_distractor_list[keyword] = distractors\n",
        "\n",
        "index = 1\n",
        "print (\"#############################################################################\")\n",
        "print (\"NOTE::::::::  Since the algorithm might have errors along the way, wrong answer choices generated might not be correct for some questions. \")\n",
        "print (\"#############################################################################\\n\\n\")\n",
        "for each in key_distractor_list:\n",
        "    sentence = keyword_sentence_mapping[each][0]\n",
        "    pattern = re.compile(each, re.IGNORECASE)\n",
        "    output = pattern.sub( \" _______ \", sentence)\n",
        "    print (\"%s)\"%(index),output)\n",
        "    choices = [each.capitalize()] + key_distractor_list[each]\n",
        "    top4choices = choices[:4]\n",
        "    random.shuffle(top4choices)\n",
        "    optionchoices = ['a','b','c','d']\n",
        "    for idx,choice in enumerate(top4choices):\n",
        "        print (\"\\t\",optionchoices[idx],\")\",\" \",choice)\n",
        "    print (\"\\nMore options: \", choices[4:20],\"\\n\\n\")\n",
        "    index = index + 1"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#############################################################################\n",
            "NOTE::::::::  Since the algorithm might have errors along the way, wrong answer choices generated might not be correct for some questions. \n",
            "#############################################################################\n",
            "\n",
            "\n",
            "1)  _______  cut the stems into strips, pressed them, and dried them into sheets that could be rolled into scrolls.\n",
            "\t a )   Bantu\n",
            "\t b )   Algerian\n",
            "\t c )   Angolan\n",
            "\t d )   Egyptians\n",
            "\n",
            "More options:  ['Basotho', 'Beninese', 'Berber', 'Black African', 'Burundian', 'Cameroonian', 'Carthaginian', 'Chadian', 'Chewa', 'Congolese', 'Djiboutian', 'Egyptian', 'Ethiopian', 'Eurafrican', 'Ewe', 'Fulani'] \n",
            "\n",
            "\n",
            "2) In  _______ , people became slaves if they owed a debt, committed a crime, or were captured in war.\n",
            "\t a )   Egypt\n",
            "\t b )   Malawi\n",
            "\t c )   East Africa\n",
            "\t d )   Somalia\n",
            "\n",
            "More options:  ['Togo', 'Zimbabwe', 'Gabon', 'Ghana', 'Lake Tanganyika', 'Ottoman Empire', 'Mozambique', 'Iran', 'Israel', 'Saudi Arabia', 'Lebanon', 'Turkey', 'Iraq', 'Levant', 'Syria', 'Jordan'] \n",
            "\n",
            "\n",
            "3) The  _______  provided so well for Egyptians that sometimes they had surpluses, or more goods than they needed.\n",
            "\t a )   Port Sudan\n",
            "\t b )   Omdurman\n",
            "\t c )   Nile\n",
            "\t d )   Nyala\n",
            "\n",
            "More options:  ['Khartoum', 'Nubian Desert', 'Darfur', 'Libyan Desert', 'Kordofan', 'Gulu', 'Buganda', 'Entebbe', 'Jinja', 'Lake Edward', 'entebbe', 'gulu', 'kayunga', 'Upper Egypt', 'Suez Canal', 'Aswan High Dam'] \n",
            "\n",
            "\n",
            "4) Legend says a king named Narmer united  _______  and Lower Egypt.\n",
            "\t a )   Upper Berth\n",
            "\t b )   Upper\n",
            "\t c )   Lower Berth\n",
            "\n",
            "More options:  [] \n",
            "\n",
            "\n",
            "5) Legend says a king named Narmer united Upper and  _______ .\n",
            "\t a )   Libyan Desert\n",
            "\t b )   Upper Egypt\n",
            "\t c )   Lower egypt\n",
            "\t d )   Suez Canal\n",
            "\n",
            "More options:  ['Aswan High Dam', 'Eastern Desert', 'Aswan', 'Lake Nasser', 'Suez', 'Thebes', 'Sinai'] \n",
            "\n",
            "\n",
            "6) It begins near the equator in  _______  and flows north to the Mediterranean Sea.\n",
            "\t a )   Australia\n",
            "\t b )   Africa\n",
            "\t c )   Old World\n",
            "\t d )   Eurasia\n",
            "\n",
            "More options:  [] \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vmyuf4duwXUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}